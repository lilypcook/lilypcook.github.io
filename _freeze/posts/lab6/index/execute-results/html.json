{
  "hash": "00bc24b4a51a7471e5707b3e1c4547a6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 6 - Spicy\"\nformat: html\ndescription: \"Performing Many Different Versions of an Analysis\"\nauthor:\n  - name: Lily Cook\ndate: 05-12-2025\ncategories: [Advanced R] \nimage: ../../media/zigzag.jpg\ndraft: false \nexecute: \n  echo: true\n  warning: false\nembed-resources: true\neditor: source\n---\n\n\n\n\nThis assignment will challenge your function writing abilities. I'm not going to lie, these functions are difficult but well within your reach. I do, however, want to recognize that not everyone is interested in being a \"virtuoso\" with their function writing. So, there are two options for this week's lab:\n\n-   **Option 1:** Complete this lab assignment in search of virtuoso status with your function writing\n-   **Option 2:** Complete one of the difficult functions (Exercise 1 or Exercise 2) and complete the \"Alternative Lab 6\".\n\n# Setting the Stage\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(purrr)\n```\n:::\n\n\n\n\nMy number one use case for writing functions and iteration / looping is to perform some exploration or modeling repeatedly for different \"tweaked\" versions. For example, our broad goal might be to fit a linear regression model to our data. However, there are often multiple choices that we have to make in practice:\n\n-   Keep missing values or fill them in (imputation)?\n-   Filter out outliers in one or more variables?\n\nWe can map these choices to **arguments** in a custom model-fitting function:\n\n-   `impute`: TRUE or FALSE\n-   `remove_outliers`: TRUE or FALSE\n\nA function that implements the analysis and allows for variation in these choices:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_model <- function(df, impute, remove_outliers, mod) {\n    if (impute) {\n        df <- some_imputation_function(df)\n    }\n    \n    if (remove_outliers) {\n        df <- function_for_removing_outliers(df)\n    }\n    \n    lm(mod, data = df)\n}\n```\n:::\n\n\n\n\n# Helper Functions\n\n**Exercise 1:** Write a function that removes outliers in a dataset. The user should be able to supply the dataset, the variables to remove outliers from, and a threshold on the number of SDs away from the mean used to define outliers. *Hint 1: You will need to calculate a z-score to filter the values!* *Hint 2: You might want to consider specifying a default value (e.g., 3) for `sd_thresh`.*\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove_outliers <- function(df, ..., sd_thresh = 3) {\n  \n  selected_cols <- rlang::enquos(...) #suggested by discord, specify rlang after class discussion\n\n  # make sure that at least one variable input\n  if (length(selected_cols) == 0) {\n    stop(\"Specify at least one variable to remove outliers from\")\n  }\n\n  df_filtered <- df\n\n  for (col_quo in selected_cols) {\n    # column names as string to filter \n    col_name <- rlang::as_name(col_quo)\n\n    #make sure column is in df\n    if (!col_name %in% names(df_filtered)) {\n      warning(paste(col_name, \"not found in the dataframe. Skipping.\"))\n      next\n    }\n    \n    # vectorize to check numeric (ChatGPT helped with this part)\n    col_vec <- df_filtered[[col_name]]\n\n    # check if numeric\n    if (!is.numeric(col_vec)) {\n      warning(paste(col_name, \"is not numeric. Skipping.\"))\n      next\n    }\n\n    col_mean <- mean(col_vec, na.rm = TRUE)\n    col_sd <- sd(col_vec, na.rm = TRUE)\n\n    z_scores <- (col_vec - col_mean) / col_sd\n\n    # identify obs that are ouliers\n    remove <- abs(z_scores) >= sd_thresh\n\n    # remove outliers from df \n    df_filtered <- df_filtered[-remove, ]\n  }\n\n  return(df_filtered)\n}\n```\n:::\n\n\n\n\n## Testing Your Function!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Testing how your function handles multiple input variables\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,936 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 2  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 3  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 4  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 5  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n 6  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n 7  0.3  Good      J     SI1      64      55   339  4.25  4.28  2.73\n 8  0.23 Ideal     J     VS1      62.8    56   340  3.93  3.9   2.46\n 9  0.22 Premium   F     SI1      60.4    61   342  3.88  3.84  2.33\n10  0.31 Ideal     J     SI2      62.2    54   344  4.35  4.37  2.71\n# ℹ 53,926 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,939 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 2  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 3  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 4  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 5  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 6  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 7  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 8  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n 9  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n10  0.3  Good      J     SI1      64      55   339  4.25  4.28  2.73\n# ℹ 53,929 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_thresh = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,936 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 2  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 3  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 4  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 5  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n 6  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n 7  0.3  Good      J     SI1      64      55   339  4.25  4.28  2.73\n 8  0.23 Ideal     J     VS1      62.8    56   340  3.93  3.9   2.46\n 9  0.22 Premium   F     SI1      60.4    61   342  3.88  3.84  2.33\n10  0.31 Ideal     J     SI2      62.2    54   344  4.35  4.37  2.71\n# ℹ 53,926 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n## Demonstrating error message for not-found column \nremove_outliers(diamonds, \n                lol, \n                x, \n                y, \n                z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,937 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 2  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 3  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 4  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 5  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 6  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n 7  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n 8  0.3  Good      J     SI1      64      55   339  4.25  4.28  2.73\n 9  0.23 Ideal     J     VS1      62.8    56   340  3.93  3.9   2.46\n10  0.22 Premium   F     SI1      60.4    61   342  3.88  3.84  2.33\n# ℹ 53,927 more rows\n```\n\n\n:::\n:::\n\n\n\n\n**Exercise 2:** Write a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. *Hint 1: You will need to use `across()` to apply your function, since the user can input multiple variables.* *Hint 2: The `replace_na()` function is helpful here!*\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimpute_missing <- function(df, ..., impute_fun = mean) {\n  selected_cols <- rlang::enquos(...)\n  \n  # warning message for no columns selected\n  if (length(selected_cols) == 0) {\n    warning(\"No columns specified for imputation, returning original dataframe\")\n    return(df)\n  }\n  \n  # selecting df columns, !!! allows for unquoting (... is usable)\n  filtered_df <- df %>% dplyr::select(!!!selected_cols)\n  col_names <- names(filtered_df)\n  \n  # warning message for when all columns do not exist\n  if (length(col_names) == 0) {\n     stop(\"Columns specified do not exist\")\n  }\n  \n  # checking is all cols numeric \n  are_numeric <- sapply(filtered_df, is.numeric)\n  if (!all(are_numeric)) {\n    # id non-numeric and warning\n    non_numeric_selected_cols <- col_names[!are_numeric]\n    stop(paste(\"The following columns are non-numeric:\", paste(non_numeric_selected_cols, collapse=\", \")))\n  }\n  \n  df_imputed <- df %>%\n    mutate(\n      across(\n        .cols = all_of(col_names), #selecting cols\n        .fns = ~ {imputation_val <- impute_fun(.x, na.rm = TRUE) #creating impute values\n                  tidyr::replace_na(.x, imputation_val) #replacing NAs\n                  }\n      ))\n  \n  return(df_imputed)\n}\n```\n:::\n\n\n\n\n## Testing Your Function!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Testing how your function handles multiple input variables\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles an input that isn't numeric\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               carrier)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in impute_missing(nycflights13::flights, arr_delay, carrier): The following columns are non-numeric: carrier\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles a non-default impute_fun\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay, \n               impute_fun = median)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n\n# Primary Function\n\n**Exercise 3:** Write a `fit_model()` function that fits a specified linear regression model for a specified dataset. The function should:\n\n-   allow the user to specify if outliers should be removed (`TRUE` or `FALSE`)\n-   allow the user to specify if missing observations should be imputed (`TRUE` or `FALSE`)\n\nIf either option is `TRUE`, your function should call your `remove_outliers()` or `impute_missing()` functions to modify the data **before** the regression model is fit.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_model <- function(df, mod_formula, remove_outliers = F, impute_missing = F, ...){\n  selected_cols <- rlang::enquos(...)\n  \n  # warning for no vars provided\n  if(length(selected_cols) == 0){\n    stop(\"Please provide variables in formula\")\n  }\n  \n  # warning if no formula provided or if not a call object\n  if(is.call(mod_formula) == F | is.null(mod_formula) == T){\n    stop(\"Model formula is not specified correctly\")\n  }\n  \n  df_filtered <- df\n  \n  # removing outliers\n  if(remove_outliers == T){\n    df_filtered <- remove_outliers(df_filtered, !!!selected_cols)\n  }\n  \n  # imputing\n  if(impute_missing == T){\n    df_filtered <- impute_missing(df_filtered, !!!selected_cols)\n  }\n  \n  #fitting model\n  model <- lm(mod_formula, data = df_filtered)\n  \n  return(model)\n}\n```\n:::\n\n\n\n\n## Testing Your Function!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_model(\n  diamonds,\n  mod_formula = price ~ carat + cut,\n  remove_outliers = TRUE,\n  impute_missing = TRUE,\n  price, \n  carat\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.47      7871.17      1239.78      -528.59       367.96        74.63  \n```\n\n\n:::\n:::\n\n\n\n\n# Iteration\n\nIn the `diamonds` dataset, we want to understand the relationship between `price` and size (`carat`). We want to explore variation along two choices:\n\n1.  The variables included in the model. We'll explore 3 sets of variables:\n\n    -   No further variables (just `price` and `carat`)\n    -   Adjusting for `cut`\n    -   Adjusting for `cut` and `clarity`\n    -   Adjusting for `cut`, `clarity`, and `color`\n\n2.  Whether or not to impute missing values\n\n3.  Whether or not to remove outliers in the `carat` variable (we'll define outliers as cases whose `carat` is over 3 SDs away from the mean).\n\n## Parameters\n\nFirst, we need to define the set of parameters we want to iterate the `fit_model()` function over. The `tidyr` package has a useful function called `crossing()` that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and `crossing()` generates all combinations. *Note that you can create a list of formula objects in R with `c(y ~ x1, y ~ x1 + x2)`.*\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_arg_combos <- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(y ~ x1, \n            y ~ x1 + x2)\n)\ndf_arg_combos\n```\n:::\n\n\n\n\n**Exercise 4:** Use `crossing()` to create the data frame of argument combinations for our analyses.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_arg_combos <- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(price ~ carat, \n            price ~ carat + cut,\n            price ~ carat + cut + clarity,\n            price ~ carat + cut + clarity + color)\n)\ndf_arg_combos\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16 × 3\n   impute remove_outliers mod      \n   <lgl>  <lgl>           <list>   \n 1 FALSE  FALSE           <formula>\n 2 FALSE  FALSE           <formula>\n 3 FALSE  FALSE           <formula>\n 4 FALSE  FALSE           <formula>\n 5 FALSE  TRUE            <formula>\n 6 FALSE  TRUE            <formula>\n 7 FALSE  TRUE            <formula>\n 8 FALSE  TRUE            <formula>\n 9 TRUE   FALSE           <formula>\n10 TRUE   FALSE           <formula>\n11 TRUE   FALSE           <formula>\n12 TRUE   FALSE           <formula>\n13 TRUE   TRUE            <formula>\n14 TRUE   TRUE            <formula>\n15 TRUE   TRUE            <formula>\n16 TRUE   TRUE            <formula>\n```\n\n\n:::\n:::\n\n\n\n\n## Iterating Over the Parameters\n\nWe've arrived at the final step!\n\n**Exercise 5:** Use `pmap()` from `purrr` to apply the `fit_model()` function to every combination of arguments from \\`diamonds.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npmap(df_arg_combos, fit_model, df = diamonds, price, carat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[2]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[3]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[4]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[5]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7757  \n\n\n[[6]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.47      7871.17      1239.78      -528.59       367.96        74.63  \n\n\n[[7]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.784     8472.316      713.686     -334.533      188.544        1.705  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4012.037    -1821.966      917.545     -429.913      257.052       26.916  \n  clarity^7  \n    186.767  \n\n\n[[8]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.814     8886.379      698.795     -327.726      180.624       -1.168  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.848    -1832.466      923.155     -361.872      216.522        2.114  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.368    -1910.260     -627.961     -172.133       21.894      -86.104  \n    color^6  \n    -49.899  \n\n\n[[9]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[10]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[11]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[12]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[13]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7757  \n\n\n[[14]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.47      7871.17      1239.78      -528.59       367.96        74.63  \n\n\n[[15]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.784     8472.316      713.686     -334.533      188.544        1.705  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4012.037    -1821.966      917.545     -429.913      257.052       26.916  \n  clarity^7  \n    186.767  \n\n\n[[16]]\n\nCall:\nlm(formula = mod_formula, data = df_filtered)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.814     8886.379      698.795     -327.726      180.624       -1.168  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.848    -1832.466      923.155     -361.872      216.522        2.114  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.368    -1910.260     -627.961     -172.133       21.894      -86.104  \n    color^6  \n    -49.899  \n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}