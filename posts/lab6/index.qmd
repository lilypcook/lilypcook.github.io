---
title: "Lab 6 - Spicy"
format: html
description: "Performing Many Different Versions of an Analysis"
author:
  - name: Lily Cook
date: 05-12-2025
categories: [Advanced R] 
image: ../../media/zigzag.jpg
draft: false 
execute: 
  echo: true
  warning: false
embed-resources: true
editor: source
---

This assignment will challenge your function writing abilities. I'm not going to lie, these functions are difficult but well within your reach. I do, however, want to recognize that not everyone is interested in being a "virtuoso" with their function writing. So, there are two options for this week's lab:

-   **Option 1:** Complete this lab assignment in search of virtuoso status with your function writing
-   **Option 2:** Complete one of the difficult functions (Exercise 1 or Exercise 2) and complete the "Alternative Lab 6".

# Setting the Stage

```{r}
#| label: libraries
#| output: false

library(tidyverse)
library(purrr)

```

My number one use case for writing functions and iteration / looping is to perform some exploration or modeling repeatedly for different "tweaked" versions. For example, our broad goal might be to fit a linear regression model to our data. However, there are often multiple choices that we have to make in practice:

-   Keep missing values or fill them in (imputation)?
-   Filter out outliers in one or more variables?

We can map these choices to **arguments** in a custom model-fitting function:

-   `impute`: TRUE or FALSE
-   `remove_outliers`: TRUE or FALSE

A function that implements the analysis and allows for variation in these choices:

```{r}
#| echo: true
#| eval: false
#| label: example-code-to-motivate-function

fit_model <- function(df, impute, remove_outliers, mod) {
    if (impute) {
        df <- some_imputation_function(df)
    }
    
    if (remove_outliers) {
        df <- function_for_removing_outliers(df)
    }
    
    lm(mod, data = df)
}
```

# Helper Functions

**Exercise 1:** Write a function that removes outliers in a dataset. The user should be able to supply the dataset, the variables to remove outliers from, and a threshold on the number of SDs away from the mean used to define outliers. *Hint 1: You will need to calculate a z-score to filter the values!* *Hint 2: You might want to consider specifying a default value (e.g., 3) for `sd_thresh`.*

```{r}
#| label: exercise-1

remove_outliers <- function(df, ..., sd_thresh = 3) {
  
  selected_cols <- rlang::enquos(...) #suggested by discord, specify rlang after class discussion

  # make sure that at least one variable input
  if (length(selected_cols) == 0) {
    stop("Specify at least one variable to remove outliers from")
  }

  df_filtered <- df

  for (col_quo in selected_cols) {
    # column names as string to filter 
    col_name <- rlang::as_name(col_quo)

    #make sure column is in df
    if (!col_name %in% names(df_filtered)) {
      warning(paste(col_name, "not found in the dataframe. Skipping."))
      next
    }
    
    # vectorize to check numeric (ChatGPT helped with this part)
    col_vec <- df_filtered[[col_name]]

    # check if numeric
    if (!is.numeric(col_vec)) {
      warning(paste(col_name, "is not numeric. Skipping."))
      next
    }

    col_mean <- mean(col_vec, na.rm = TRUE)
    col_sd <- sd(col_vec, na.rm = TRUE)

    z_scores <- (col_vec - col_mean) / col_sd

    # identify obs that are ouliers
    remove <- abs(z_scores) >= sd_thresh

    # remove outliers from df 
    df_filtered <- df_filtered[-remove, ]
  }

  return(df_filtered)
}
```

## Testing Your Function!

```{r}
#| label: exercise-1-test
#| error: true

## Testing how your function handles multiple input variables
remove_outliers(diamonds, 
                price, 
                x, 
                y, 
                z)

## Testing how your function handles an input that isn't numeric
remove_outliers(diamonds, 
                price, 
                color)

## Testing how your function handles a non-default sd_thresh
remove_outliers(diamonds, 
                price,
                x, 
                y, 
                z, 
                sd_thresh = 2)

## Demonstrating error message for not-found column 
remove_outliers(diamonds, 
                lol, 
                x, 
                y, 
                z)
```

**Exercise 2:** Write a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. *Hint 1: You will need to use `across()` to apply your function, since the user can input multiple variables.* *Hint 2: The `replace_na()` function is helpful here!*

```{r}
#| label: exercise-2

impute_missing <- function(df, ..., impute_fun = mean) {
  selected_cols <- rlang::enquos(...)
  
  # warning message for no columns selected
  if (length(selected_cols) == 0) {
    warning("No columns specified for imputation, returning original dataframe")
    return(df)
  }
  
  # selecting df columns, !!! allows for unquoting (... is usable)
  filtered_df <- df %>% dplyr::select(!!!selected_cols)
  col_names <- names(filtered_df)
  
  # warning message for when all columns do not exist
  if (length(col_names) == 0) {
     stop("Columns specified do not exist")
  }
  
  # checking is all cols numeric 
  are_numeric <- sapply(filtered_df, is.numeric)
  if (!all(are_numeric)) {
    # id non-numeric and warning
    non_numeric_selected_cols <- col_names[!are_numeric]
    stop(paste("The following columns are non-numeric:", paste(non_numeric_selected_cols, collapse=", ")))
  }
  
  df_imputed <- df %>%
    mutate(
      across(
        .cols = all_of(col_names), #selecting cols
        .fns = ~ {imputation_val <- impute_fun(.x, na.rm = TRUE) #creating impute values
                  tidyr::replace_na(.x, imputation_val) #replacing NAs
                  }
      ))
  
  return(df_imputed)
}

```

## Testing Your Function!

```{r}
#| label: exercise-2-test
#| error: true

## Testing how your function handles multiple input variables
impute_missing(nycflights13::flights, 
               arr_delay, 
               dep_delay) 

## Testing how your function handles an input that isn't numeric
impute_missing(nycflights13::flights, 
               arr_delay, 
               carrier)

## Testing how your function handles a non-default impute_fun
impute_missing(nycflights13::flights, 
               arr_delay, 
               dep_delay, 
               impute_fun = median)
```

# Primary Function

**Exercise 3:** Write a `fit_model()` function that fits a specified linear regression model for a specified dataset. The function should:

-   allow the user to specify if outliers should be removed (`TRUE` or `FALSE`)
-   allow the user to specify if missing observations should be imputed (`TRUE` or `FALSE`)

If either option is `TRUE`, your function should call your `remove_outliers()` or `impute_missing()` functions to modify the data **before** the regression model is fit.

```{r}
#| label: exercise-3

fit_model <- function(df, mod_formula, remove_outliers = F, impute_missing = F, ...){
  selected_cols <- rlang::enquos(...)
  
  # warning for no vars provided
  if(length(selected_cols) == 0){
    stop("Please provide variables in formula")
  }
  
  # warning if no formula provided or if not a call object
  if(is.call(mod_formula) == F | is.null(mod_formula) == T){
    stop("Model formula is not specified correctly")
  }
  
  df_filtered <- df
  
  # removing outliers
  if(remove_outliers == T){
    df_filtered <- remove_outliers(df_filtered, !!!selected_cols)
  }
  
  # imputing
  if(impute_missing == T){
    df_filtered <- impute_missing(df_filtered, !!!selected_cols)
  }
  
  #fitting model
  model <- lm(mod_formula, data = df_filtered)
  
  return(model)
}
```

## Testing Your Function!

```{r}
#| label: exercise-3-test

fit_model(
  diamonds,
  mod_formula = price ~ carat + cut,
  remove_outliers = TRUE,
  impute_missing = TRUE,
  price, 
  carat
)

```

# Iteration

In the `diamonds` dataset, we want to understand the relationship between `price` and size (`carat`). We want to explore variation along two choices:

1.  The variables included in the model. We'll explore 3 sets of variables:

    -   No further variables (just `price` and `carat`)
    -   Adjusting for `cut`
    -   Adjusting for `cut` and `clarity`
    -   Adjusting for `cut`, `clarity`, and `color`

2.  Whether or not to impute missing values

3.  Whether or not to remove outliers in the `carat` variable (we'll define outliers as cases whose `carat` is over 3 SDs away from the mean).

## Parameters

First, we need to define the set of parameters we want to iterate the `fit_model()` function over. The `tidyr` package has a useful function called `crossing()` that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and `crossing()` generates all combinations. *Note that you can create a list of formula objects in R with `c(y ~ x1, y ~ x1 + x2)`.*

```{r}
#| label: example-crossing-arguments
#| eval: false

df_arg_combos <- crossing(
    impute = c(TRUE, FALSE),
    remove_outliers = c(TRUE, FALSE), 
    mod = c(y ~ x1, 
            y ~ x1 + x2)
)
df_arg_combos
```

**Exercise 4:** Use `crossing()` to create the data frame of argument combinations for our analyses.

```{r}
#| label: exercise-4

df_arg_combos <- crossing(
    impute = c(TRUE, FALSE),
    remove_outliers = c(TRUE, FALSE), 
    mod = c(price ~ carat, 
            price ~ carat + cut,
            price ~ carat + cut + clarity,
            price ~ carat + cut + clarity + color)
)
df_arg_combos

```

## Iterating Over the Parameters

We've arrived at the final step!

**Exercise 5:** Use `pmap()` from `purrr` to apply the `fit_model()` function to every combination of arguments from \`diamonds.

```{r}
#| label: exercise-5

pmap(df_arg_combos, fit_model, df = diamonds, price, carat)
```

